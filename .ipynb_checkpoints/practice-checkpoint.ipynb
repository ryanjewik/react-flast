{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616c0341-76b1-4df3-a625-9a583069df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1593425-bc2b-48f2-bd4e-4873c4b96a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "\n",
    "boto3_bedrock = boto3.client('bedrock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e60d99db-faad-4915-a2de-91af8827b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import json \n",
    "\n",
    "bedrock_runtime = boto3.client('bedrock-runtime')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "164405f1-0ed8-474b-8749-64f9de09363c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you'd like to try your own prompt, edit this parameter!\n",
    "prompt_data = \"\"\"Human: Write me 500 word paragraph about making strong business decisions as a leader.\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0a1f7b8-d252-4447-b774-513bee3de602",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_API_body = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\", \n",
    "    \"max_tokens\": int(500/0.75),\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt_data\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a2b149c-91d9-4f46-93ff-4d6b9a1d32b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a 504 word paragraph about making strong business decisions as a leader:\n",
      "\n",
      "As a leader, making strong, well-informed business decisions is one of the most critical skills you can possess. The decisions you make will have a direct impact on the success and trajectory of your organization, so it's essential to approach the decision-making process with care, diligence, and a strategic mindset.\n",
      "\n",
      "First and foremost, effective business leaders understand the importance of gathering comprehensive data and information before making a decision. This means researching your market, analyzing industry trends, assessing your company's financial standing, and evaluating both the short-term and long-term implications of potential choices. Relying on accurate, up-to-date data allows you to make informed, rational decisions, rather than relying on gut instinct or guesswork.\n",
      "\n",
      "Strong leaders also have the ability to think critically and objectively about the situation at hand. This means considering multiple perspectives, weighing the pros and cons of each option, and identifying potential risks and challenges. It's important to set aside personal biases or emotions and focus on what's truly best for the business, even if that means making a difficult or unpopular decision.\n",
      "\n",
      "Another key aspect of effective decision-making is the ability to quickly adapt to changing circumstances. In today's fast-paced business environment, conditions can shift rapidly, and leaders must be agile enough to pivot their strategy as needed. This might involve revisiting a previous decision, adjusting your course of action, or exploring entirely new approaches. The ability to respond proactively to new information or unexpected events is a hallmark of successful business leadership.\n",
      "\n",
      "Perhaps most importantly, great leaders understand that decision-making is a collaborative process. While the ultimate responsibility may rest on your shoulders, it's essential to seek input and feedback from your team, advisors, and stakeholders. Involving others not only helps you gain a more well-rounded perspective, but it also fosters a sense of buy-in and ownership among your employees. When people feel their voice has been heard and their expertise valued, they're more likely to rally behind the final decision and work diligently to see it through.\n",
      "\n",
      "Finally, truly exceptional leaders are not afraid to make tough, unpopular decisions when necessary. Sometimes, the right choice for the business may be the most difficult one, whether it involves making staffing changes, adjusting pricing, or pivoting your entire strategy. In these situations, it's crucial to communicate your rationale clearly, empathize with those impacted, and remain steadfast in your commitment to the long-term success of the organization.\n",
      "\n",
      "Effective decision-making is the hallmark of great business leadership. By approaching this critical skill with rigor, objectivity, and a collaborative mindset, you can position your organization for lasting success, even in the face of complex and ever-changing market conditions.None"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output, display, display_markdown, Markdown\n",
    "\n",
    "body = json.dumps(messages_API_body)\n",
    "modelId = \"anthropic.claude-3-haiku-20240307-v1:0\"  # (Change this to try different model versions)\n",
    "accept = \"application/json\"\n",
    "contentType = \"application/json\"\n",
    "\n",
    "try:\n",
    "\n",
    "    response = bedrock_runtime.invoke_model_with_response_stream(\n",
    "        body=body, modelId=modelId, accept=accept, contentType=contentType\n",
    "    )\n",
    "    \n",
    "    stream = response.get('body')\n",
    "    \n",
    "    \n",
    "    output = []\n",
    "\n",
    "    if stream:\n",
    "        for event in stream:\n",
    "            chunk = event.get('chunk')\n",
    "            if chunk:\n",
    "                chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "                if 'delta' in chunk_obj:\n",
    "                    delta_obj = chunk_obj.get('delta', None)\n",
    "                    if delta_obj:\n",
    "                        text = delta_obj.get('text', None)\n",
    "                        print(text,end='')\n",
    "                        if not text :\n",
    "                            break\n",
    "                    # output.append(text[0]) if type(text) is list and len(text)>0 else output.append('')\n",
    "                    # display_markdown(Markdown(text))\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "\n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "\n",
    "    else:\n",
    "        raise error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f559957-cab0-4c8b-b5e9-a968a07ee615",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -qU boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d323def-ba96-4b54-af31-16b10d4883c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running boto3 version: 1.35.24\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sys\n",
    "print('Running boto3 version:', boto3.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d58fd404-f188-4bf8-86ff-79232e2f4b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using region:  us-west-2\n"
     ]
    }
   ],
   "source": [
    "boto3_session = boto3.session.Session()\n",
    "region = boto3_session.region_name\n",
    "\n",
    "print('Using region: ', region)\n",
    "\n",
    "bedrock = boto3.client(\n",
    "    service_name = 'bedrock-runtime',\n",
    "    region_name = region,\n",
    "    )\n",
    "\n",
    "MODEL_IDS = [\n",
    "    #\"amazon.titan-tg1-lite\",\n",
    "    \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "    \"meta.llama3-1-8b-instruct-v1:0\",\n",
    "    #\"meta.llama-3-8b-instruct\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d076b3f-4e82-4a13-890d-ced4ad8a31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_bedrock_model(client, id, prompt, max_tokens=2000, temperature=0, top_p=0.9):\n",
    "    response = \"\"\n",
    "    try:\n",
    "        response = client.converse(\n",
    "            modelId=id,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"text\": prompt\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ],\n",
    "            inferenceConfig={\n",
    "                \"temperature\": temperature,\n",
    "                \"maxTokens\": max_tokens,\n",
    "                \"topP\": top_p\n",
    "            }\n",
    "            #additionalModelRequestFields={\n",
    "            #}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        result = \"Model invocation error\"\n",
    "    try:\n",
    "        result = response['output']['message']['content'][0]['text'] \\\n",
    "        + '\\n--- Latency: ' + str(response['metrics']['latencyMs']) \\\n",
    "        + 'ms - Input tokens:' + str(response['usage']['inputTokens']) \\\n",
    "        + ' - Output tokens:' + str(response['usage']['outputTokens']) + ' ---\\n'\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        result = \"Output parsing error\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80b033b3-b5de-42e2-8e15-1873b3e9fc85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is the capital of Italy?\n",
      "\n",
      "Model: anthropic.claude-3-haiku-20240307-v1:0\n",
      "The capital of Italy is Rome.\n",
      "--- Latency: 293ms - Input tokens:14 - Output tokens:10 ---\n",
      "\n",
      "Model: anthropic.claude-3-sonnet-20240229-v1:0\n",
      "The capital of Italy is Rome.\n",
      "--- Latency: 390ms - Input tokens:14 - Output tokens:10 ---\n",
      "\n",
      "Model: meta.llama3-1-8b-instruct-v1:0\n",
      "\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "--- Latency: 223ms - Input tokens:21 - Output tokens:9 ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = (\"What is the capital of Italy?\")\n",
    "print(f'Prompt: {prompt}\\n')\n",
    "\n",
    "for i in MODEL_IDS:\n",
    "    response = invoke_bedrock_model(bedrock, i, prompt)\n",
    "    print(f'Model: {i}\\n{response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05f78bff-620b-43c0-b24e-22ee82a7d60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_IDS = [\n",
    "    \"meta.llama3-1-8b-instruct-v1:0\",\n",
    "    \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "650a53d9-68d6-406e-a827-f145b5dbbc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_bedrock_model_stream(client, id, prompt, max_tokens=2000, temperature=0, top_p=0.9):\n",
    "    response = \"\"\n",
    "    response = client.converse_stream(\n",
    "        modelId=id,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        inferenceConfig={\n",
    "            \"temperature\": temperature,\n",
    "            \"maxTokens\": max_tokens,\n",
    "            \"topP\": top_p\n",
    "        }\n",
    "    )\n",
    "    # Extract and print the response text in real-time.\n",
    "    for event in response['stream']:\n",
    "        if 'contentBlockDelta' in event:\n",
    "            chunk = event['contentBlockDelta']\n",
    "            sys.stdout.write(chunk['delta']['text'])\n",
    "            sys.stdout.flush()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "140035a2-2353-4e91-9206-34353530b5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is the capital of Italy?\n",
      "\n",
      "\n",
      "\n",
      "Model: meta.llama3-1-8b-instruct-v1:0\n",
      "\n",
      "\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "Model: anthropic.claude-3-haiku-20240307-v1:0\n",
      "The capital of Italy is Rome.\n",
      "\n",
      "Model: anthropic.claude-3-sonnet-20240229-v1:0\n",
      "The capital of Italy is Rome."
     ]
    }
   ],
   "source": [
    "prompt = (\"What is the capital of Italy?\")\n",
    "print(f'Prompt: {prompt}\\n')\n",
    "\n",
    "for i in MODEL_IDS:\n",
    "    print(f'\\n\\nModel: {i}')\n",
    "    invoke_bedrock_model_stream(bedrock, i, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0288557-9851-4985-9633-8593283c0aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
